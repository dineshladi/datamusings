<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Logistic Regression from Scratch | DataMusings</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Logistic Regression from Scratch" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Implementing logistic regression in Python using numpy library" />
<meta property="og:description" content="Implementing logistic regression in Python using numpy library" />
<link rel="canonical" href="https://dineshladi.github.io/datamusings/ml/jupyter/2020/04/24/logistic-regression.html" />
<meta property="og:url" content="https://dineshladi.github.io/datamusings/ml/jupyter/2020/04/24/logistic-regression.html" />
<meta property="og:site_name" content="DataMusings" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-24T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Implementing logistic regression in Python using numpy library","headline":"Logistic Regression from Scratch","@type":"BlogPosting","dateModified":"2020-04-24T00:00:00-05:00","datePublished":"2020-04-24T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://dineshladi.github.io/datamusings/ml/jupyter/2020/04/24/logistic-regression.html"},"url":"https://dineshladi.github.io/datamusings/ml/jupyter/2020/04/24/logistic-regression.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/datamusings/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://dineshladi.github.io/datamusings/feed.xml" title="DataMusings" /><link rel="shortcut icon" type="image/x-icon" href="/datamusings/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Logistic Regression from Scratch | DataMusings</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Logistic Regression from Scratch" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Implementing logistic regression in Python using numpy library" />
<meta property="og:description" content="Implementing logistic regression in Python using numpy library" />
<link rel="canonical" href="https://dineshladi.github.io/datamusings/ml/jupyter/2020/04/24/logistic-regression.html" />
<meta property="og:url" content="https://dineshladi.github.io/datamusings/ml/jupyter/2020/04/24/logistic-regression.html" />
<meta property="og:site_name" content="DataMusings" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-24T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Implementing logistic regression in Python using numpy library","headline":"Logistic Regression from Scratch","@type":"BlogPosting","dateModified":"2020-04-24T00:00:00-05:00","datePublished":"2020-04-24T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://dineshladi.github.io/datamusings/ml/jupyter/2020/04/24/logistic-regression.html"},"url":"https://dineshladi.github.io/datamusings/ml/jupyter/2020/04/24/logistic-regression.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://dineshladi.github.io/datamusings/feed.xml" title="DataMusings" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    // remove paragraph tags in rendered toc (happens from notebooks)
    var toctags = document.querySelectorAll(".toc-entry")
    toctags.forEach(e => (e.firstElementChild.innerText = e.firstElementChild.innerText.replace('¶', '')))
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/datamusings/">DataMusings</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/datamusings/about/">About Me</a><a class="page-link" href="/datamusings/search/">Search</a><a class="page-link" href="/datamusings/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Logistic Regression from Scratch</h1><p class="page-description">Implementing logistic regression in Python using numpy library</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-24T00:00:00-05:00" itemprop="datePublished">
        Apr 24, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/datamusings/categories/#ML">ML</a>
        &nbsp;
      
        <a class="category-tags-link" href="/datamusings/categories/#jupyter">jupyter</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/dineshladi/datamusings/tree/master/_notebooks/2020-04-24-logistic-regression.ipynb" role="button">
<img class="notebook-badge-image" src="/datamusings/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div><div class="px-2">
    <a href="https://colab.research.google.com/github/dineshladi/datamusings/blob/master/_notebooks/2020-04-24-logistic-regression.ipynb">
        <img class="notebook-badge-image" src="/datamusings/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Introduction">Introduction </a></li>
<li class="toc-entry toc-h2"><a href="#Estimate-Regression-Coefficients">Estimate Regression Coefficients </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-24-logistic-regression.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h2>
<p>Logistic Regression is a statistical method to predict qualitative response using one or more independent variables. Instead of predicting the response directly, Logistic Regression models probability that the response belongs to a particular category. In logistic regression, we use logistic function.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The logistic function will always producr an S shaped curve, so we always get a sensible prediction. $p(X)$ is sometimes also called sigmoid function.</p>
<p>
$$ \log\Big(\frac{p(X)}{1-p(X)}\Big) = w^TX + c $$
</p>
<p>
$$z = w^TX + c $$
</p>
<p>
$$ p(X) = \frac{1}{1 + e^{-z}} $$
</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse-hide</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">normalize</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse-hide</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="sd">'''Sigmoid function maps from a value between 0 and 1'''</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Sigmoid Function"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Estimate-Regression-Coefficients">
<a class="anchor" href="#Estimate-Regression-Coefficients" aria-hidden="true"><span class="octicon octicon-link"></span></a>Estimate Regression Coefficients<a class="anchor-link" href="#Estimate-Regression-Coefficients"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A method called <strong>maximum likelihood</strong> is to estimate the unknown coefficients. The idea behind this method is to estimate coefficients such that predicted probability $\hat{p}(x_i)$ of each observation corresponds closely as possible to the observed value of response variable for the same observation. In other words, we estimate coefficients such that $p(X)$ yields a number close to 1 for the observations with actual response value 1 and a number close to 0 for the observations with actual response value 0. The mathematical eequation for the likelihood function is</p>
<p>
$$ \ell(W) = \prod_{i;y_i = 1} p(x_i) \prod_{i;y_i = 0} ( 1 - p(x_i)) $$
</p>
<p>The $W$ estimates are chosen to maximize the likelihood function.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Manipulating the above constraint, we arrive at Cross Entropy Loss for binary classification case.
\begin{equation}
L(y,\hat{y}) = -\frac{1}{N} \sum_{i=1}^N y_i \log(\hat{y_i}) + (1-y_i)\log(\hat{y_i})
\end{equation}</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">cross_entropy_loss</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="sd">'''Cross entropy loss function'''</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">y</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">h</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">total_loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Use chain rule to calculate gradient of loss</p>
\begin{equation}
\frac{\partial{L}}{\partial{w_i}} = \frac{\partial{L}}{\partial{\hat{y}}} \frac{\partial{\hat{y}}}{\partial{z}} \frac{\partial{z}}{\partial{w}}
\end{equation}<p>Examining each factor in turn</p>
\begin{equation}
\frac{\partial{L}}{\partial{\hat{y_i}}} = \frac{-y_i}{\hat{y_i}} + \frac{1-y_i}{1-\hat{y_i}} 
\end{equation}\begin{equation}
\frac{\partial{L}}{\partial{\hat{y_i}}} =  \frac{\hat{y_i}-y_i}{\hat{y_i}(1-\hat{y_i})} 
\end{equation}\begin{equation}
\frac{\partial{\hat{y}}}{\partial{z}}  =  \hat{y_i}(1-\hat{y_i}) 
\end{equation}\begin{equation}
\frac{\partial{z}}{\partial{w}}  =  x_i 
\end{equation}<p>Multiplying all the indivdual terms, you get</p>
\begin{equation}
\frac{\partial{L}}{\partial{w_i}} = (\hat{y_i}-y_i)x_i
\end{equation}
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="sd">'''Gradient for cross entropy loss'''</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">h</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gradient</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We are gonnna use a algorithm called <strong>batch gradient descent</strong> to find the optimal weights.</p>
<p>
$$ \Delta w_{i} = -\eta  \frac{\partial L}{\partial w_{i}} $$
</p>
<p>
$$ w_{i} := w_{i} + \Delta w_{i} $$
</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">update_weights</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">n_iters</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">loss_threshold</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">):</span>
    <span class="c1">## Initialize the weights with zero values</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iters</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">cross_entropy_loss</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loss after iteration </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> is </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="n">loss_threshold</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">return</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="p">(</span><span class="n">probs</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">100</span><span class="o">*</span><span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">true</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets load some binary classification data from <code>sklearn.datasets</code> and split the data into train test split.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cancer_data</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="n">x</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer_data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> 
                                                    <span class="n">cancer_data</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> 
                                                    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> 
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets call the update weights function to find the optimal weights that minimizes cross entropy loss</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">update_weights</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">n_iters</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">loss_threshold</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Loss after iteration 0 is 281.55
Loss after iteration 1000 is 87.93
Loss after iteration 2000 is 83.59
Loss after iteration 3000 is 81.78
Loss after iteration 4000 is 80.63
Loss after iteration 5000 is 79.76
Loss after iteration 6000 is 79.06
Loss after iteration 7000 is 78.46
Loss after iteration 8000 is 77.94
Loss after iteration 9000 is 77.47
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets use the model to generate predictions for the test data and see what kind of accuracies are we reaching.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">normalize</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy on test data is </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracy on test data is 93.706
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="dineshladi/datamusings"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/datamusings/ml/jupyter/2020/04/24/logistic-regression.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/datamusings/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/datamusings/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/datamusings/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A data musings blog using Python and R.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/dineshladi" title="dineshladi"><svg class="svg-icon grey"><use xlink:href="/datamusings/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/dineshladi" title="dineshladi"><svg class="svg-icon grey"><use xlink:href="/datamusings/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/ladidinesh" title="ladidinesh"><svg class="svg-icon grey"><use xlink:href="/datamusings/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
